# ğŸ§  Explainable ADNET using Graph Attention Autoencoders (X-ADNET)

> A PyTorch Geometric implementation of an **Explainable Anomaly Detection Network (ADNET)** that integrates **Graph Attention Networks (GATs)** and **Autoencoders** for interpretable graph-based anomaly detection.

---

## ğŸš€ Overview

This project implements **X-ADNET (Explainable ADNET)** â€” a graph neural network model that combines **autoencoder-based anomaly detection** with **attention-based explainability**.  
It enables **node-level anomaly detection** on graph datasets like **Cora** while also providing **attention-based visual explanations** for why certain nodes are flagged as anomalous.

---

### ğŸŒŸ Key Highlights
- ğŸ§© Built on **Graph Attention Networks (GATConv)** and **Graph Convolutional Networks (GCNConv)**  
- ğŸ•µï¸â€â™‚ï¸ Performs **structure and attribute reconstruction** for anomaly detection  
- ğŸ” Provides **explainability via attention weights**  
- ğŸ“ˆ Visualizes anomalous nodes and influential neighbors using **NetworkX** and **PyVis**  
- ğŸ’¡ Supports **interactive visual explanations** for each anomaly node  

---

## ğŸ§¬ Model Architecture

nput Graph â†’ GAT Encoder â†’ Latent Embeddings (H)
â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â”‚
Structure Decoder (AÌ‚) Attribute Decoder (XÌ‚)
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â†“
Combined Loss (L)


### ğŸ”¹ Components

- **Encoder:** GAT layer with attention weights (`GATConv`)
- **Structure Decoder:** Reconstructs adjacency matrix (AÌ‚)
- **Attribute Decoder:** Reconstructs node features (XÌ‚)
- **Loss Function:**  
  \[
  L = (1 - \alpha) \cdot E_S + \alpha \cdot E_A
  \]  
  where  
  \( E_S \) = Structure loss (BCE)  
  \( E_A \) = Attribute loss (MSE)

---

## ğŸ› ï¸ Installation

### ğŸ”§ Prerequisites
Make sure you have **Python 3.10+** and **pip** installed.
 âš™ï¸ Setup Instructions

```bash
# Clone this repository
git clone https://github.com/yourusername/X-ADNET.git
cd X-ADNET

# Install required dependencies
pip install torch torchvision torchaudio
pip install torch-geometric
pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-$(python -c "import torch; print(torch.__version__)")
pip install networkx matplotlib pyvis

ğŸ“˜ Usage
You can run the notebook directly in Google Colab â¤µï¸
ğŸ”— Open in Google Colab
Or run it locally:
jupyter notebook sna.ipynb


ğŸ§  Training Workflow


Load the dataset (Cora from PyTorch Geometric)


Train the X-ADNET model for 100 epochs


Compute anomaly scores for each node


Visualize explainable attention graphs for top anomalies



ğŸ“Š Sample Training Output
EpochTotal LossStructure LossAttribute Loss100.35270.69310.0123500.35260.69310.01201000.35260.69310.0120

ğŸ” Example: Top Anomalous Nodes
--- Top 5 Most Anomalous Nodes ---
Rank 1: Node ID 677 (Normalized Score: 1.0000)
Rank 2: Node ID 442 (Normalized Score: 0.8966)
Rank 3: Node ID 921 (Normalized Score: 0.8754)
Rank 4: Node ID 1794 (Normalized Score: 0.8723)
Rank 5: Node ID 2308 (Normalized Score: 0.8701)


ğŸ¯ Explainability Module
The attention mechanism in GATConv provides direct insight into which neighbors influenced the modelâ€™s decision.
Example: Explaining Node 677
Node 677 has 2 neighbors (incl. self-loop).
This node's embedding was built by paying attention to:
- 0.509 â†’ neighbor Node 954
- 0.491 â†’ itself (self-loop)

ğŸ•¸ï¸ Visual Attention Graph
Use the built-in visualization function to generate interactive explanations:
visualize_explanation(target_node_id=677, file_name="explanation.html")

Output:


ğŸ”´ Red node = detected anomaly


ğŸŸ¢ Green nodes = influential neighbors


Edge color/thickness = attention weight


ğŸ“¸ Add screenshot of attention visualization here

ğŸ’¡ Example Visualization
import networkx as nx
import matplotlib.pyplot as plt

<p align="center">
  <img src="https://raw.githubusercontent.com/yourusername/X-ADNET/main/assets/xadnet_graph.png" alt="X-ADNET Visualization" width="700"/>
</p>
Fig: Visualization of anomaly explanation highlighting key influential nodes.

ğŸ§© Technologies Used
TechnologyDescriptionPyTorch GeometricGraph neural network frameworkGATConv & GCNConvCore layers for graph learningNetworkXGraph structure visualizationPyVisInteractive, web-based explainabilityMatplotlibStatic plots and heatmapsCora DatasetBenchmark dataset for node classification

ğŸ“š References


Ding, K., et al. â€œDeep Anomaly Detection on Attributed Networks.â€ IJCAI 2019.


Velickovic, P., et al. â€œGraph Attention Networks.â€ ICLR 2018.


Kipf, T. N., & Welling, M. â€œSemi-Supervised Classification with Graph Convolutional Networks.â€ ICLR 2017.


PyTorch Geometric Documentation â€” https://pytorch-geometric.readthedocs.io



ğŸ§‘â€ğŸ’» Author
Daksh Jain
ğŸ“§ Email: daksh.jain@example.com
ğŸ”— LinkedIn | GitHub

ğŸª„ Future Enhancements


ğŸ”¹ Multi-head attention for richer context


ğŸ”¹ Integration with heterogeneous graph datasets


ğŸ”¹ Streamlit-based interactive explainability dashboard



ğŸ License
This project is licensed under the MIT License â€” feel free to use and modify it for research or educational purposes.

<p align="center">
  â­ If you found this project helpful, donâ€™t forget to star the repo!
</p>

---

Would you like me to:
- Add a **cover banner** (like â€œX-ADNET â€” Explainable Graph Anomaly Detectionâ€) at the top with your GitHub username?  
or  
- Generate a **dark mode themed README** version (with gradient dividers and visual emojis)?  

I can instantly style it for **maximum visual appeal** depending on how you plan to present it (portfolio vs academic).
